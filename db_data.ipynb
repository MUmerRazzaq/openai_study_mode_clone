{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0571e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import SQLiteSession\n",
    "\n",
    "session = SQLiteSession(\"user_123\", \"src/openai_study_mode_clone/study_agent_session.db\")\n",
    "\n",
    "msg = await session.get_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3c03355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'i want to lean python', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': \"Awesome! Python is a great choice.\\n\\nTo get started, what's your experience with programming? Have you coded before, or is this your first time?\", 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}, {'content': 'hy', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': \"Got it. Since you're new to coding, we'll start with the basics. Here’s the plan:\\n\\n1.  **What is Python?** Briefly, what it is and why it's popular.\\n2.  **Basic Syntax:** Learn to write simple Python commands.\\n3.  **Variables:** How to store and use data.\\n4.  **Mini-exercise:** A small coding problem to check your understanding.\\n\\nReady? First, what do you think Python is used for? Any ideas?\", 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}, {'content': 'ok', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': 'Okay! So, Python is a versatile programming language used for many things, like:\\n\\n*   **Web development:** Creating websites and web applications.\\n*   **Data analysis:** Analyzing and visualizing data.\\n*   **Machine learning:** Building AI models.\\n*   **Automation:** Automating repetitive tasks.\\n\\nOne of the reasons Python is so popular is its simple syntax, which makes it easier to read and write compared to other languages.\\n\\nNow, let\\'s dive into some basic syntax. The simplest thing we can do in Python is print something to the screen.\\n\\nTry this: What do you think will happen if you type `print(\"Hello, world!\")` in Python?\\n', 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}, {'content': 'ok', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': 'What do you think will happen if you type `print(\"Hello, world!\")` in Python?\\n', 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}, {'content': 'ok', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': 'I see you said \"ok\" again. Are you able to try typing `print(\"Hello, world!\")` into a Python interpreter or a Python script and running it?\\n\\nIf you don\\'t have Python set up yet, you can use an online interpreter like [https://www.programiz.com/python-programming/online-compiler/](https://www.programiz.com/python-programming/online-compiler/) to test it out.\\n\\nLet me know what happens!\\n', 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}, {'content': 'it working', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': 'Great! You\\'ve just run your first Python command. `print()` is a built-in function that displays whatever is inside the parentheses.\\n\\nNow, let\\'s talk about **variables**. Variables are like containers that store data. For example, you can store a number or a string (text) in a variable.\\n\\nHere\\'s how you create a variable in Python:\\n\\n```python\\nmessage = \"Hello, Python!\"\\nnumber = 10\\n```\\n\\nIn this example, `message` is a variable that stores the string `\"Hello, Python!\"`, and `number` is a variable that stores the number `10`.\\n\\nHow would you create a variable called `name` and store your name in it?\\n', 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}, {'content': 'I want to learn JS', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': \"Okay, switching gears to JavaScript!\\n\\nTo make sure I'm on the right track, are you also new to JavaScript (like you are to Python), or do you have some coding experience already?\\n\", 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}, {'content': 'yes', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': \"Understood. So you're new to JavaScript as well. No problem, we'll start with the basics, just like we were doing with Python.\\n\\nHere’s the plan:\\n\\n1.  **What is JavaScript?** Briefly, what it is and why it's important.\\n2.  **Basic Syntax:** Learn to write simple JavaScript commands.\\n3.  **Variables:** How to store and use data.\\n4.  **Mini-exercise:** A small coding problem to check your understanding.\\n\\nReady? First, what do you think JavaScript is used for? Any ideas?\\n\", 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}, {'content': 'hy', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': 'Hmm, I see you just typed \"hy\" again.\\n\\nTo make sure we\\'re on the same page, I\\'m asking what you think JavaScript is used for. Do you have any ideas? If you\\'re not sure, that\\'s totally fine! I can give you a hint.\\n', 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}, {'content': 'hy', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': \"Okay, it seems like you might be having some trouble responding.\\n\\nI'm going to give you a quick explanation of what JavaScript is used for, and then we can move on. Sound good?\\n\", 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}, {'content': 'yes', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': 'Great! So, JavaScript is mainly used for:\\n\\n*   **Making websites interactive:** Adding things like animations, buttons that do things, and updating content without reloading the page.\\n*   **Web applications:** Building complex applications that run in a browser (like Google Maps or online games).\\n*   **Server-side development:** Running JavaScript on servers to handle requests and manage data.\\n*   **Mobile apps:** Creating mobile apps using frameworks like React Native.\\n\\nBasically, JavaScript makes websites dynamic and engaging.\\n\\nNow, let\\'s look at some basic syntax. Just like with Python, we can start with a simple command to print something to the screen. In JavaScript, we use `console.log()` for this.\\n\\nWhat do you think will happen if you type `console.log(\"Hello, world!\");` in JavaScript?\\n', 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}, {'content': 'next', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': 'Okay, I see you want to move on. Just to check, did you try running the `console.log(\"Hello, world!\");` command in a JavaScript environment?\\n\\nIf not, I recommend trying it out in your browser\\'s console (usually accessed by pressing F12 and going to the \"Console\" tab) or in an online JavaScript editor like CodePen or JSFiddle.\\n\\nLet me know if you want to try that first, or if you\\'d really rather just move on!\\n', 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}, {'content': 'what is html', 'role': 'user'}, {'id': '__fake_id__', 'content': [{'annotations': [], 'text': \"Okay, let's switch to HTML.\\n\\nTo make sure I understand, are you interested in learning HTML now instead of JavaScript?\\n\", 'type': 'output_text'}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}]\n"
     ]
    }
   ],
   "source": [
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21086c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in msg:\n",
    "    if item[\"role\"] == \"user\":\n",
    "        print(f\"User message found: {item['content']}\")\n",
    "    # messages = item['messages']\n",
    "    if item[\"role\"] == \"assistant\":\n",
    "        # print(f\"Assistant message found: {item.get('content')}\")\n",
    "        message = item.get('content')[0].get('text')\n",
    "        print(f\"Assistant message found: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b29c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import AsyncOpenAI, OpenAIChatCompletionsModel\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "def get_llm_client() -> AsyncOpenAI:\n",
    "    \"\"\"\n",
    "    Initializes and returns the asynchronous LLM client.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the required API key or base URL environment variables are not set.\n",
    "\n",
    "    Returns:\n",
    "        AsyncOpenAI: An instance of the async LLM client.\n",
    "    \"\"\"\n",
    "    # The API key for the service. The variable name suggests a Gemini model provider\n",
    "    # that uses an OpenAI-compatible API.\n",
    "    api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GEMINI_API_KEY environment variable not set.\")\n",
    "\n",
    "    # The base URL for the chat completion endpoint.\n",
    "    base_url = os.environ.get(\"LLM_CHAT_COMPLETION_URL\")\n",
    "    if not base_url:\n",
    "        raise ValueError(\"LLM_CHAT_COMPLETION_URL environment variable not set.\")\n",
    "\n",
    "    return AsyncOpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "def get_llm_model(client: AsyncOpenAI) -> OpenAIChatCompletionsModel:\n",
    "    \"\"\"\n",
    "    Initializes and returns the chat completions model.\n",
    "\n",
    "    Args:\n",
    "        client (AsyncOpenAI): The client to use for the model.\n",
    "\n",
    "    Returns:\n",
    "        OpenAIChatCompletionsModel: An instance of the chat completions model.\n",
    "    \"\"\"\n",
    "    model_name = os.environ.get(\"LLM_MODEL\", \"gemini-2.0-flash\")\n",
    "    return OpenAIChatCompletionsModel(openai_client=client, model=model_name)\n",
    "\n",
    "# Create singleton instances to be imported by other modules\n",
    "client: AsyncOpenAI = get_llm_client()\n",
    "model: OpenAIChatCompletionsModel = get_llm_model(client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner , SQLiteSession , ItemHelpers , \n",
    "# from openai_study_mode_clone.config.llm_model_config import model\n",
    "\n",
    "study_agent : Agent = Agent(\n",
    "    name=\"Study Agent\",\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant for a student studying a specific topic. Your goal is to provide explanations, answer questions, and guide the student through their learning process.\n",
    "---\"\"\",\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "\n",
    "async def study_agent_service(user_input: str , user_id: str) -> str:\n",
    "    # session = SQLiteSession(user_id, \"study_agent_session.db\")\n",
    "    response = await Runner(\n",
    "        starting_agent=study_agent,\n",
    "        input=user_input,\n",
    "        # session=session\n",
    "    )\n",
    "    # session.close()\n",
    "    # return response.final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "883f84ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Streaming Responses ===\n",
      "=== Run started ===\n",
      "=== Processing events ===\n",
      "Text chunk: Okay\n",
      "Text chunk: , let's talk about the Pythagorean Theorem!\n",
      "\n",
      "**In a nutshell:**\n",
      "Text chunk:  The Pythagorean Theorem is a fundamental relationship in geometry that connects the sides of a right\n",
      "Text chunk:  triangle.\n",
      "\n",
      "**What it says:** In a right triangle (a triangle with one angle that is exactly 90 degrees), the square of the length of\n",
      "Text chunk:  the longest side (called the hypotenuse) is equal to the sum of the squares of the lengths of the other two sides (called the legs or cathet\n",
      "Text chunk: us).\n",
      "\n",
      "**The Formula:**\n",
      "a² + b² = c²\n",
      "\n",
      "Where:\n",
      "*   `a` and `b` are the lengths of the two shorter sides (legs) of the right triangle.\n",
      "*   `c`\n",
      "Text chunk:  is the length of the longest side (hypotenuse), which is opposite the right angle.\n",
      "\n",
      "**Let's break it down with a simple example:**\n",
      "\n",
      "Imagine a right triangle where one leg (`a`) is 3 units long and\n",
      "Text chunk:  the other leg (`b`) is 4 units long.\n",
      "\n",
      "1.  **Square the legs:**\n",
      "    *   a² = 3² = 9\n",
      "    *   b² = 4² = 16\n",
      "\n",
      "2.  **Add the squares:**\n",
      "    *   a² + b²\n",
      "Text chunk:  = 9 + 16 = 25\n",
      "\n",
      "3.  **Find the square root:**\n",
      "    *   c = √25 = 5\n",
      "\n",
      "So, the length of the hypotenuse (`c`) is 5 units.\n",
      "\n",
      "**Why is it important?**\n",
      "\n",
      "*   **Geometry\n",
      "Text chunk:  and Trigonometry:** It's a cornerstone of geometry and trigonometry.\n",
      "*   **Real-World Applications:** Used in construction, navigation, and many other fields to calculate distances, angles, and relationships between objects.\n",
      "\n",
      "**Do you have any specific questions about the theorem, like how to apply it, or where\n",
      "Text chunk:  it comes from?**\n"
     ]
    }
   ],
   "source": [
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "\n",
    "responses = Runner.run_streamed(\n",
    "    starting_agent=study_agent,\n",
    "    input=\"What is the Pythagorean theorem?\",\n",
    "    # session=session\n",
    ")\n",
    "print(\"=== Streaming Responses ===\")\n",
    "print(\"=== Run started ===\")\n",
    "print(\"=== Processing events ===\")\n",
    "async for event in responses.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance( event.data,ResponseTextDeltaEvent ):\n",
    "        print(f\"Text chunk: {event.data.delta}\")\n",
    "    # print(f\"Event: {event}\")\n",
    "    # # print(f\"Event data: {event.data}\")\n",
    "    # print(f\"Event type: {event.type}\")\n",
    "    # print(\"=== Event processed ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e01e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def study_agent_service(user_input: str , user_id: str):\n",
    "     responses = Runner.run_streamed(\n",
    "        starting_agent=study_agent,\n",
    "        input=user_input,\n",
    "        # session=session\n",
    "    )\n",
    "    \n",
    "    for event in responses.stream_events():\n",
    "        # We'll ignore the raw responses event deltas\n",
    "        if event.type == \"raw_response_event\":\n",
    "            continue\n",
    "            # When the agent updates, print that\n",
    "        elif event.type == \"agent_updated_stream_event\":\n",
    "            (f\"Agent updated: {event.new_agent.name}\")\n",
    "            continue\n",
    "        # When items are generated, print them\n",
    "        elif event.type == \"run_item_stream_event\":\n",
    "            if event.item.type == \"tool_call_item\":\n",
    "                print(\"-- Tool was called\")\n",
    "            elif event.item.type == \"tool_call_output_item\":\n",
    "                print(f\"-- Tool output: {event.item.output}\")\n",
    "            elif event.item.type == \"message_output_item\":\n",
    "                print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
    "            else:\n",
    "                pass  # Ignore other event types\n",
    "\n",
    "            print(\"=== Run complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6940120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[WeatherAgentLifecycle] Agent WeatherAgent starting with context: RunContextWrapper(context=None, usage=Usage(requests=0, input_tokens=0, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=0, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=0))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[WeatherAgentLifecycle] LLM call starting with system prompt: You are a helpful assistant. Talk about weather and let news_agent handle the news things and input items: [{'content': \"What's the latest news about Qwen Code - seems like it can give though time to claude code.\", 'role': 'user'}]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[WeatherAgentLifecycle] LLM call ended with response: ModelResponse(output=[ResponseFunctionToolCall(arguments='{}', call_id='function-call-757011918939407599', name='transfer_to_newsagent', type='function_call', id='__fake_id__', status=None)], usage=Usage(requests=0, input_tokens=0, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=0, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=0), response_id='__fake_id__')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[NewsAgentLifecycle] Agent NewsAgent starting with context: RunContextWrapper(context=None, usage=Usage(requests=0, input_tokens=0, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=0, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=0))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[NewsAgentLifecycle] LLM call starting with system prompt: You are a helpful news assistant. and input items: [{'content': \"What's the latest news about Qwen Code - seems like it can give though time to claude code.\", 'role': 'user'}, {'arguments': '{}', 'call_id': 'function-call-757011918939407599', 'name': 'transfer_to_newsagent', 'type': 'function_call', 'id': '__fake_id__'}, {'call_id': 'function-call-757011918939407599', 'output': '{\"assistant\": \"NewsAgent\"}', 'type': 'function_call_output'}]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[NewsAgentLifecycle] LLM call ended with response: ModelResponse(output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='It looks like your request has been transferred to our NewsAgent. Please wait a moment while it gathers the latest information regarding Qwen Code and its comparison to Claude.', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], usage=Usage(requests=0, input_tokens=0, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=0, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=0), response_id='__fake_id__')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[NewsAgentLifecycle] Agent NewsAgent ended with output: It looks like your request has been transferred to our NewsAgent. Please wait a moment while it gathers the latest information regarding Qwen Code and its comparison to Claude.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel, function_tool, AgentHooks, RunContextWrapper\n",
    "\n",
    "_: bool = load_dotenv(find_dotenv())\n",
    "\n",
    "# ONLY FOR TRACING\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "gemini_api_key: str = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "\n",
    "# 1. Which LLM Service?\n",
    "external_client: AsyncOpenAI = AsyncOpenAI(\n",
    "    api_key=gemini_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    ")\n",
    "\n",
    "# 2. Which LLM Model?\n",
    "llm_model: OpenAIChatCompletionsModel = OpenAIChatCompletionsModel(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    openai_client=external_client\n",
    ")\n",
    "\n",
    "\n",
    "# Agent Lifecycle Callbacks/Hooks\n",
    "class HelloAgentHooks(AgentHooks):\n",
    "    def __init__(self, lifecycle_name: str):\n",
    "        self.lifecycle_name = lifecycle_name\n",
    "        \n",
    "    async def on_start(self, context, agent):\n",
    "        context.context\n",
    "        print(f\"\\n\\n[{self.lifecycle_name}] Agent {agent.name} starting with context: {context}\\n\\n\")\n",
    "        \n",
    "    async def on_llm_start(self, context: RunContextWrapper, agent, system_prompt, input_items):\n",
    "        print(f\"\\n\\n[{self.lifecycle_name}] LLM call starting with system prompt: {system_prompt} and input items: {input_items}\\n\\n\")\n",
    "        \n",
    "    async def on_llm_end(self, context, agent, response):\n",
    "        print(f\"\\n\\n[{self.lifecycle_name}] LLM call ended with response: {response}\\n\\n\")\n",
    "        \n",
    "    async def on_end(self, context, agent, output):\n",
    "        print(f\"\\n\\n[{self.lifecycle_name}] Agent {agent.name} ended with output: {output}\\n\\n\")\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"A simple function to get the weather for a user.\"\"\"\n",
    "    return f\"The weather for {city} is sunny.\"\n",
    "\n",
    "\n",
    "\n",
    "news_agent: Agent = Agent(\n",
    "    name=\"NewsAgent\",\n",
    "    instructions=\"You are a helpful news assistant.\",\n",
    "    model=llm_model,\n",
    "    hooks=HelloAgentHooks(\"NewsAgentLifecycle\")\n",
    ")\n",
    "\n",
    "\n",
    "base_agent: Agent = Agent(\n",
    "    name=\"WeatherAgent\",\n",
    "    instructions=\"You are a helpful assistant. Talk about weather and let news_agent handle the news things\",\n",
    "    model=llm_model,\n",
    "    tools=[get_weather],\n",
    "    hooks=HelloAgentHooks(\"WeatherAgentLifecycle\"),\n",
    "    handoffs=[news_agent]\n",
    ")\n",
    "\n",
    "res = Runner.run_streamed(base_agent, \"What's the latest news about Qwen Code - seems like it can give though time to claude code.\")\n",
    "# print(res.last_agent.name)\n",
    "# print(res.final_output)\n",
    "\n",
    "# Now check the trace in \n",
    "\n",
    "async for event in responses.stream_events():\n",
    "    # We'll ignore the raw responses event deltas\n",
    "    if event.type == \"raw_response_event\":\n",
    "        continue\n",
    "    # When the agent updates, print that\n",
    "    elif event.type == \"agent_updated_stream_event\":\n",
    "        print(f\"Agent updated: {event.new_agent.name}\")\n",
    "        continue\n",
    "    # When items are generated, print them\n",
    "    elif event.type == \"run_item_stream_event\":\n",
    "        if event.item.type == \"tool_call_item\":\n",
    "            print(\"-- Tool was called\")\n",
    "        elif event.item.type == \"tool_call_output_item\":\n",
    "            print(f\"-- Tool output: {event.item.output}\")\n",
    "        elif event.item.type == \"message_output_item\":\n",
    "            print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
    "        else:\n",
    "            pass  # Ignore other event types\n",
    "\n",
    "            print(\"=== Run complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed0686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_study_mode_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
